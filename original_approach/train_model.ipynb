{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE = \"001000100000011101000000111011101001010000011111001110000101000100100\"\n",
    "INPUT_SHAPE = 28\n",
    "\n",
    "LEARNING_RATE_DICT = {\n",
    "    0: 1 * 10 ** (-5), 1: 5 * 10 ** (-5),\n",
    "    2: 1 * 10 ** (-4), 3: 5 * 10 ** (-4),\n",
    "    4: 1 * 10 ** (-3), 5: 5 * 10 ** (-3),\n",
    "    6: 1 * 10 ** (-2), 7: 5 * 10 ** (-2),\n",
    "}\n",
    "\n",
    "DENSE_TYPE_DICT = {\n",
    "    0: \"recurrent\", 1: \"LSTM\", 2: \"GRU\", 3: \"feed-forward\"\n",
    "}\n",
    "\n",
    "REGULARIZATION_DICT = {\n",
    "    0: \"l1\", 1: \"l2\", 2: \"l1l2\", 3: None\n",
    "}\n",
    "\n",
    "ACTIVATION_DICT = {\n",
    "    0: \"relu\",\n",
    "    1: \"linear\"\n",
    "}\n",
    "\n",
    "RGL_DCT = {\n",
    "            0: regularizers.l1(1e-4),\n",
    "            1: regularizers.l2(1e-4),\n",
    "            2: regularizers.l1_l2(l1=1e-4, l2=1e-4),\n",
    "            3: None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_to_decimal(bits):\n",
    "    return int(\"\".join(map(str, bits)), 2)\n",
    "\n",
    "def get_batch_size(gene):\n",
    "        return [25, 50, 100, 15][binary_to_decimal(gene[:2])]\n",
    "\n",
    "def get_convol_layers_num(gene):\n",
    "    return 1 + binary_to_decimal(gene[2:4])\n",
    "\n",
    "def get_kernels_num(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[4 + i * 10: 4 + i * 10 + 3]\n",
    "        result.append(2 ** (binary_to_decimal(binary) + 1))\n",
    "    return result\n",
    "\n",
    "def get_kernel_sizes(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[7 + i * 10: 7 + i * 10 + 3]\n",
    "        result.append(2 + binary_to_decimal(binary))\n",
    "    return result\n",
    "\n",
    "def get_pooling(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[10 + i * 10: 10 + i * 10 + 3]\n",
    "        result.append(1 + binary_to_decimal(binary))\n",
    "    return result\n",
    "\n",
    "def get_convol_activation(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[13 + i * 10: 13 + i * 10 + 1]\n",
    "        result.append(ACTIVATION_DICT[binary_to_decimal(binary)])\n",
    "    return result\n",
    "\n",
    "def get_dense_layers_num(gene):\n",
    "    return 1 + binary_to_decimal([gene[44]])\n",
    "\n",
    "def get_dense_type(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[45 + i * 9: 45 + i * 9 + 2]\n",
    "        result.append(DENSE_TYPE_DICT[binary_to_decimal(binary)])\n",
    "    return result\n",
    "\n",
    "def get_neurons_num(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[47 + i * 9: 47 + i * 9 + 3]\n",
    "        result.append(2 ** (binary_to_decimal(binary) + 3))\n",
    "    return result\n",
    "\n",
    "def get_dense_activation(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[50 + i * 9: 50 + i * 9 + 1]\n",
    "        result.append(ACTIVATION_DICT[binary_to_decimal(binary)])\n",
    "    return result\n",
    "\n",
    "def get_regularization(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[51 + i * 9: 51 + i * 9 + 2]\n",
    "        result.append(binary_to_decimal(binary))\n",
    "    return result\n",
    "\n",
    "def get_dropout(gene, layers_num):\n",
    "    result = []\n",
    "    for i in range(layers_num):\n",
    "        binary = gene[53 + i * 9: 53 + i * 9 + 1]\n",
    "        result.append(binary_to_decimal(binary) / 2)\n",
    "    return result\n",
    "\n",
    "def get_optimizer(gene):\n",
    "    binary = gene[63: 66]\n",
    "    return binary_to_decimal(binary)\n",
    "\n",
    "def get_learning_rate(gene):\n",
    "    binary = gene[66: 69]\n",
    "    return LEARNING_RATE_DICT[binary_to_decimal(binary)]\n",
    "\n",
    "def get_components(gene):\n",
    "    dct = {}\n",
    "\n",
    "    dct[\"b\"] = get_batch_size(gene)\n",
    "\n",
    "    # Convolutional layers\n",
    "    dct[\"nc\"] = get_convol_layers_num(gene)\n",
    "    dct[\"ck\"] = get_kernels_num(gene, dct[\"nc\"])\n",
    "    dct[\"cs\"] = get_kernel_sizes(gene, dct[\"nc\"])\n",
    "    dct[\"cp\"] = get_pooling(gene, dct[\"nc\"])\n",
    "    dct[\"ca\"] = get_convol_activation(gene, dct[\"nc\"])\n",
    "\n",
    "    # Dense layers\n",
    "    dct[\"nd\"] = get_dense_layers_num(gene)\n",
    "    dct[\"dt\"] = get_dense_type(gene, dct[\"nd\"])\n",
    "    dct[\"dn\"] = get_neurons_num(gene, dct[\"nd\"])\n",
    "    dct[\"da\"] = get_dense_activation(gene, dct[\"nd\"])\n",
    "    dct[\"dd\"] = get_dropout(gene, dct[\"nd\"])\n",
    "    dct[\"dr\"] = get_regularization(gene, dct[\"nd\"])\n",
    "\n",
    "    # Learning parameters\n",
    "    dct[\"n\"] = get_learning_rate(gene)\n",
    "    dct[\"f\"] = get_optimizer(gene)\n",
    "\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dense_layers(components, model):\n",
    "    new_model = model\n",
    "    if components[\"nd\"] == 1:\n",
    "\n",
    "        if components[\"dt\"][0] == \"feed-forward\":\n",
    "            new_model.add(layers.Flatten())\n",
    "            new_model.add(\n",
    "                layers.Dense(components[\"dn\"][0], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"recurrent\":\n",
    "            last_output = new_model.layers[-1].output_shape\n",
    "            new_model.add(\n",
    "                tf.keras.layers.Reshape((last_output[1] * last_output[2], last_output[3]), \n",
    "                input_shape=last_output\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][0], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]],\n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"GRU\":\n",
    "            last_output = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape((\n",
    "                last_output[1] * last_output[2], last_output[3]), \n",
    "                input_shape=last_output\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][0], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]],\n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"LSTM\":\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0]\n",
    "            )))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Flatten())\n",
    "    else:\n",
    "\n",
    "        if components[\"dt\"][0] == \"feed-forward\" and components[\"dt\"][1] == \"feed-forward\":\n",
    "            new_model.add(layers.Flatten())\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][0], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]],\n",
    "                activation=components[\"da\"][0]))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][1], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]],\n",
    "                activation=components[\"da\"][1]))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"feed-forward\" and components[\"dt\"][1] == \"recurrent\":\n",
    "            new_model.add(layers.Flatten())\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape((\n",
    "                last_shape[1] // 2, 2), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]],\n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"feed-forward\" and components[\"dt\"][1] == \"GRU\":\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][0], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]],\n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape((\n",
    "                last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][1], \n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]],\n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"feed-forward\" and components[\"dt\"][1] == \"LSTM\":\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            )))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Flatten())\n",
    "\n",
    "        if components[\"dt\"][0] == \"recurrent\" and components[\"dt\"][1] == \"feed-forward\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0]\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"recurrent\" and components[\"dt\"][1] == \"recurrent\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"recurrent\" and components[\"dt\"][1] == \"GRU\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"recurrent\" and components[\"dt\"][1] == \"LSTM\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.LSTM(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"GRU\" and components[\"dt\"][1] == \"feed-forward\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"GRU\" and components[\"dt\"][1] == \"recurrent\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"GRU\" and components[\"dt\"][1] == \"GRU\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"GRU\" and components[\"dt\"][1] == \"LSTM\":\n",
    "            last_shape = new_model.layers[-1].output_shape\n",
    "            new_model.add(tf.keras.layers.Reshape(\n",
    "                (last_shape[1] * last_shape[2], last_shape[3]), \n",
    "                input_shape=last_shape\n",
    "            ))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "                return_sequences=True\n",
    "            ))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.LSTM(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"LSTM\" and components[\"dt\"][1] == \"feed-forward\":\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "            )))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Flatten())\n",
    "            new_model.add(layers.Dense(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"LSTM\" and components[\"dt\"][1] == \"recurrent\":\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "            )))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.SimpleRNN(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"LSTM\" and components[\"dt\"][1] == \"GRU\":\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "            )))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.GRU(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "\n",
    "        if components[\"dt\"][0] == \"LSTM\" and components[\"dt\"][1] == \"LSTM\":\n",
    "            new_model.add(layers.TimeDistributed(layers.LSTM(\n",
    "                components[\"dn\"][0],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][0]], \n",
    "                activation=components[\"da\"][0],\n",
    "            )))\n",
    "            if components[\"dd\"][0] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.LSTM(\n",
    "                components[\"dn\"][1],\n",
    "                kernel_regularizer=RGL_DCT[components[\"dr\"][1]], \n",
    "                activation=components[\"da\"][1]\n",
    "            ))\n",
    "            if components[\"dd\"][1] == 0.5:\n",
    "                new_model.add(layers.Dropout(0.5))\n",
    "            new_model.add(layers.Flatten())\n",
    "\n",
    "    new_model.add(layers.Dense(10))\n",
    "\n",
    "    return new_model\n",
    "\n",
    "def build_model(components):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(\n",
    "            components[\"ck\"][0],\n",
    "            (components[\"cs\"][0], components[\"cs\"][0]),\n",
    "            activation=components[\"ca\"][0],\n",
    "            input_shape=(28, 28, 1)\n",
    "        ))\n",
    "        model.add(layers.MaxPooling2D((components[\"cp\"][0], components[\"cp\"][0])))\n",
    "\n",
    "        for i in range(1, components[\"nc\"]):\n",
    "            model.add(layers.Conv2D(\n",
    "                components[\"ck\"][i],\n",
    "                (components[\"cs\"][i], components[\"cs\"][i]),\n",
    "                activation=components[\"ca\"][i],\n",
    "            ))\n",
    "            model.add(layers.MaxPooling2D((components[\"cp\"][i], components[\"cp\"][i])))\n",
    "\n",
    "        model = add_dense_layers(components, model)\n",
    "\n",
    "        return model\n",
    "\n",
    "def get_optimizers(function, lr):\n",
    "        learning_rate = lr\n",
    "        if function == 0:\n",
    "            opt = optimizers.SGD(learning_rate=learning_rate)\n",
    "        elif function == 1:\n",
    "            opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.1)\n",
    "        elif function == 2:\n",
    "            opt = optimizers.SGD(learning_rate=learning_rate, nesterov=True)\n",
    "        elif function == 3:\n",
    "            opt = optimizers.Adagrad(learning_rate=learning_rate)\n",
    "        elif function == 4:\n",
    "            opt = optimizers.Adamax(learning_rate=learning_rate)\n",
    "        elif function == 5:\n",
    "            opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif function == 6:\n",
    "            opt = optimizers.Adadelta(learning_rate=learning_rate)\n",
    "        elif function == 7:\n",
    "            opt = optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "        return opt\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "    x_train, x_test = x_train.astype(\"float32\"), x_test.astype(\"float32\")\n",
    "    x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()\n",
    "components = get_components(GENE)\n",
    "model = build_model(components)\n",
    "opt = get_optimizers(components[\"f\"], components[\"n\"])\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "batch_size = components[\"b\"]\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), batch_size=batch_size)\n",
    "_, test_acc = model.evaluate(x_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
